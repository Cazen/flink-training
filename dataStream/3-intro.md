---
title: DataStream API Connectors
layout: page
permalink: /dataStream/3-intro.html
---

Flink features connectors for several exernal storage systems to ingest and emit data streams. In this lesson you will learn 

* which connectors Flink provides and their capabilities,
* how to include and use source and sink connectors in your program, and
* what to consider when implementing custom stream sources and sinks. 

For the programming exercise you will

* setup local Apache Kafka and Elasticseach instances,
* connect two streaming programs through Kafka, and
* write data to Elasticsearch and visualize it with Kibana

<iframe src="//www.slideshare.net/slideshow/embed_code/key/o8jb5Wb5iPK4ui" width="680" height="571" frameborder="0" marginwidth="0" marginheight="0" scrolling="no"></iframe>

[Download slides as PDF]({{site.baseurl}}/slides/flink_stream_connectors.pdf)

[-> Continue to hands-on session]({{site.baseurl}}/dataStream/3-handsOn.html)

### References

- [Kafka + Flink: A Practical, How-To Guide](https://data-artisans.com/blog/kafka-flink-a-practical-how-to)
- [Building real-time dashboard applications with Apache Flink, Elasticsearch, and Kibana](https://www.elastic.co/blog/building-real-time-dashboard-applications-with-apache-flink-elasticsearch-and-kibana)

- [Streaming Connectors (docs)]({{ site.docs }}/dev/connectors/index.html)